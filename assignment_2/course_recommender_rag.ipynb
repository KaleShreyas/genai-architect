{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17874137",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aecaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd5939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73137461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae7035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb36d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc06f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417d8d4",
   "metadata": {},
   "source": [
    "# Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "azure_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e681a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variables\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = azure_api_key\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = azure_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d1394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a32d33",
   "metadata": {},
   "source": [
    "# Load CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238bce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"assignment2dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9bd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(dir_path):\n",
    "    \"\"\"\n",
    "    Load PDF documents from the specified directory using PyMuPDFLoader.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of loaded documents.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the directory does not exist.\n",
    "        Exception: For other loading errors.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
    "    try:\n",
    "        loader = CSVLoader(file_path=dir_path, source_column=\"course_id\")\n",
    "        return loader.load()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks using RecursiveCharacterTextSplitter.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of documents to split.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of document chunks. Returns empty list if no documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not documents:\n",
    "            return []\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "        return text_splitter.split_documents(documents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting documents: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1e2e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C001', 'row': 0}, page_content='course_id: C001\\ntitle: Foundations of Machine Learning\\ndescription: Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.'), Document(metadata={'source': 'C002', 'row': 1}, page_content='course_id: C002\\ntitle: Deep Learning with TensorFlow and Keras\\ndescription: Explore neural network architectures using TensorFlow and Keras frameworks. This course covers feedforward networks, convolutional neural networks, recurrent neural networks, and transfer learning. Learn to build, train, evaluate, and optimize deep learning models for image classification, sequence modeling, and text processing. Includes hands-on labs and real-world project implementations with interactive exercises.'), Document(metadata={'source': 'C003', 'row': 2}, page_content='course_id: C003\\ntitle: Natural Language Processing Fundamentals\\ndescription: Dive into NLP techniques for processing and understanding human language. You will learn tokenization, stemming, lemmatization, part-of-speech tagging, named entity recognition, and sentiment analysis. The course includes transformer architectures, attention mechanisms, and fine-tuning pre-trained language models. Hands-on Python labs use Hugging Face and spaCy for end-to-end natural language pipelines and projects.'), Document(metadata={'source': 'C004', 'row': 3}, page_content='course_id: C004\\ntitle: Computer Vision and Image Processing\\ndescription: Learn the principles of computer vision and image processing. Topics include filtering, edge detection, feature extraction, image segmentation, object detection, and image classification using CNNs. Hands-on labs in Python leverage OpenCV, scikit-image, and TensorFlow. By project’s end, you will build a pipeline to analyze and classify images, detect objects, and perform real-time video processing.'), Document(metadata={'source': 'C005', 'row': 4}, page_content='course_id: C005\\ntitle: Reinforcement Learning Basics\\ndescription: Get introduced to reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods. Learn to formulate environments, design reward functions, and implement agents using OpenAI Gym and TensorFlow. Through guided labs you’ll train agents for classic control tasks and grid-world scenarios, exploring exploration-exploitation trade-offs and model-free learning techniques.'), Document(metadata={'source': 'C006', 'row': 5}, page_content='course_id: C006\\ntitle: Data Engineering on AWS\\ndescription: Build scalable data pipelines using AWS services. This course covers S3 data lakes, AWS Glue ETL jobs, AWS Lambda for serverless transformations, Amazon Redshift for warehousing, and AWS Kinesis for streaming ingestion. You’ll design end-to-end pipelines, automate workflows with AWS Step Functions, and monitor performance using CloudWatch, enabling robust, cost-effective data engineering solutions on the AWS cloud.'), Document(metadata={'source': 'C007', 'row': 6}, page_content='course_id: C007\\ntitle: Cloud Computing with Azure\\ndescription: Master Microsoft Azure’s core services: virtual machines, Azure Functions, Azure SQL Database, Cosmos DB, and Azure Kubernetes Service. Learn to deploy scalable web applications, configure networking and security, and implement infrastructure-as-code with ARM templates. Hands-on labs guide you through resource provisioning, cost management, and best practices for high availability and disaster recovery in Azure.'), Document(metadata={'source': 'C008', 'row': 7}, page_content='course_id: C008\\ntitle: DevOps Practices and CI/CD\\ndescription: Adopt DevOps methodologies to accelerate software delivery. Explore version control with Git, continuous integration with Jenkins or GitHub Actions, infrastructure-as-code with Terraform, and automated testing frameworks. You’ll implement CI/CD pipelines, container registry integration, and blue-green deployments. Through practical labs, learn monitoring with Prometheus and Grafana, fostering a culture of collaboration and rapid iteration.'), Document(metadata={'source': 'C009', 'row': 8}, page_content='course_id: C009\\ntitle: Containerization with Docker and Kubernetes\\ndescription: Learn container fundamentals with Docker: images, containers, and Compose. Then advance to Kubernetes for orchestration: pods, deployments, services, and ingress. This course covers cluster provisioning, autoscaling, rolling updates, and Helm chart packaging. Hands-on labs deploy microservices architectures on a local or cloud-based Kubernetes cluster, ensuring reliability, scalability, and streamlined DevOps workflows.'), Document(metadata={'source': 'C010', 'row': 9}, page_content='course_id: C010\\ntitle: APIs and Microservices Architecture\\ndescription: Design and implement RESTful and GraphQL APIs using Node.js, Express, or Python FastAPI. Learn microservices patterns: service discovery, circuit breakers, and API gateways. Topics include containerized deployment, versioning strategies, and security best practices (OAuth2, JWT). Labs guide you through building, testing, and deploying interconnected services, enabling scalable, maintainable distributed systems.'), Document(metadata={'source': 'C011', 'row': 10}, page_content='course_id: C011\\ntitle: Big Data Analytics with Spark\\ndescription: Process and analyze large datasets using Apache Spark and PySpark. The course covers RDDs, DataFrames, Spark SQL, and MLlib for machine learning at scale. You’ll learn cluster deployment on YARN or Kubernetes, performance tuning, and structured streaming for real-time analytics. Hands-on projects include building ETL pipelines and interactive dashboards, unlocking insights from big data.'), Document(metadata={'source': 'C012', 'row': 11}, page_content='course_id: C012\\ntitle: SQL for Data Analysis\\ndescription: Master SQL querying for data analysis and reporting. Topics include SELECT statements, JOINs, subqueries, window functions, CTEs, and aggregate functions. Practice on PostgreSQL or MySQL to manipulate data, generate summary statistics, and create analytical views. Labs cover query optimization, indexing strategies, and writing complex reports, empowering you to derive actionable insights from relational data.'), Document(metadata={'source': 'C013', 'row': 12}, page_content='course_id: C013\\ntitle: NoSQL Databases and MongoDB\\ndescription: Explore NoSQL paradigms: key-value, document, column-family, and graph databases. Deep dive into MongoDB: CRUD operations, indexing, aggregation pipeline, replication, and sharding. You’ll design flexible schemas for modern applications, implement transactions, and optimize performance. Through hands-on exercises, build a highly available, horizontally scalable document store and apply best practices for data modeling.'), Document(metadata={'source': 'C014', 'row': 13}, page_content='course_id: C014\\ntitle: Data Visualization with Tableau\\ndescription: Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.'), Document(metadata={'source': 'C015', 'row': 14}, page_content='course_id: C015\\ntitle: Business Intelligence with Power BI\\ndescription: Leverage Microsoft Power BI to build dynamic business intelligence solutions. Cover data ingestion, Power Query transformations, DAX calculations, and interactive report design. You’ll publish dashboards to the Power BI service, set up data refresh schedules, and manage security. Practical labs simulate enterprise scenarios, enabling you to deliver actionable insights at scale.'), Document(metadata={'source': 'C016', 'row': 15}, page_content='course_id: C016\\ntitle: Python Programming for Data Science\\ndescription: Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.'), Document(metadata={'source': 'C017', 'row': 16}, page_content='course_id: C017\\ntitle: R Programming and Statistical Analysis\\ndescription: Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.'), Document(metadata={'source': 'C018', 'row': 17}, page_content='course_id: C018\\ntitle: Product Management Essentials\\ndescription: Understand the product lifecycle from ideation to launch. Topics cover market research, roadmap planning, agile development, and stakeholder management. Learn to write user stories, prioritize features, and measure success with KPIs. Hands-on case studies guide you through creating product requirement documents, conducting customer interviews, and iterating based on feedback to drive product-market fit.'), Document(metadata={'source': 'C019', 'row': 18}, page_content='course_id: C019\\ntitle: Agile and Scrum Mastery\\ndescription: Adopt Agile frameworks to enhance team productivity. This course covers Scrum roles, ceremonies, artifacts, and scaling with SAFe. Learn backlog grooming, sprint planning, retrospectives, and agile metrics. Interactive simulations and group exercises help you practice facilitation, conflict resolution, and continuous improvement, equipping you to lead high-performing agile teams in dynamic environments.'), Document(metadata={'source': 'C020', 'row': 19}, page_content='course_id: C020\\ntitle: User Experience (UX) Design Principles\\ndescription: Learn UX design fundamentals: user research, personas, journey mapping, wireframing, and prototyping. Utilize tools like Figma to create interactive mockups. Topics include usability testing, accessibility standards, and design systems. Through project-based labs, you’ll design and test intuitive interfaces, apply heuristics, and iterate based on user feedback to craft delightful digital experiences.'), Document(metadata={'source': 'C021', 'row': 20}, page_content='course_id: C021\\ntitle: Cybersecurity Fundamentals\\ndescription: Get introduced to cybersecurity principles: threat modeling, encryption, network security, and incident response. Learn about common vulnerabilities (OWASP Top 10), secure coding practices, and vulnerability assessment tools. Hands-on labs include configuring firewalls, running penetration tests with Kali Linux, and implementing multi-factor authentication, preparing you to protect systems and data against modern cyber threats.'), Document(metadata={'source': 'C022', 'row': 21}, page_content='course_id: C022\\ntitle: Internet of Things (IoT) Development\\ndescription: Explore IoT architecture, sensors, and edge computing. Use Raspberry Pi or Arduino to collect data, process it with MQTT, and store it in cloud services. Topics include device provisioning, security, and real-time analytics. Hands-on projects build smart home prototypes and industrial monitoring solutions, teaching you end-to-end IoT development and deployment best practices.'), Document(metadata={'source': 'C023', 'row': 22}, page_content='course_id: C023\\ntitle: Blockchain Technology and Smart Contracts\\ndescription: Understand blockchain fundamentals: cryptographic hashing, consensus algorithms, and distributed ledgers. Learn to develop smart contracts using Solidity on Ethereum. Topics include token standards (ERC-20, ERC-721), decentralized application patterns, and security best practices. Hands-on labs deploy contracts, interact via Web3.js, and build a simple decentralized marketplace.'), Document(metadata={'source': 'C024', 'row': 23}, page_content='course_id: C024\\ntitle: Augmented and Virtual Reality Development\\ndescription: Dive into AR/VR concepts, device ecosystems, and development frameworks like Unity and Unreal Engine. Learn to build immersive experiences, handle 3D assets, and implement input interactions. Topics cover spatial computing, UI/UX for XR, and performance optimization. Through labs, you’ll create both AR and VR prototypes for education, training, or entertainment use cases.'), Document(metadata={'source': 'C025', 'row': 24}, page_content='course_id: C025\\ntitle: MLOps: Productionizing Machine Learning\\ndescription: Master the practices needed to deploy and maintain ML models at scale. Topics include model versioning with MLflow, containerization, CI/CD for ML, monitoring with Prometheus, and data drift detection. You’ll build end-to-end pipelines that automate training, testing, deployment, and governance, ensuring robust, reproducible, and compliant machine learning systems in production environments.')]\n"
     ]
    }
   ],
   "source": [
    "# Load and split documents\n",
    "documents = load_documents(dir_path)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84812fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Content: course_id: C001\n",
      "title: Foundations of Machine Learning\n",
      "description: Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.\n",
      "Source: C001\n",
      "Row Content: course_id: C002\n",
      "title: Deep Learning with TensorFlow and Keras\n",
      "description: Explore neural network architectures using TensorFlow and Keras frameworks. This course covers feedforward networks, convolutional neural networks, recurrent neural networks, and transfer learning. Learn to build, train, evaluate, and optimize deep learning models for image classification, sequence modeling, and text processing. Includes hands-on labs and real-world project implementations with interactive exercises.\n",
      "Source: C002\n",
      "Row Content: course_id: C003\n",
      "title: Natural Language Processing Fundamentals\n",
      "description: Dive into NLP techniques for processing and understanding human language. You will learn tokenization, stemming, lemmatization, part-of-speech tagging, named entity recognition, and sentiment analysis. The course includes transformer architectures, attention mechanisms, and fine-tuning pre-trained language models. Hands-on Python labs use Hugging Face and spaCy for end-to-end natural language pipelines and projects.\n",
      "Source: C003\n",
      "Row Content: course_id: C004\n",
      "title: Computer Vision and Image Processing\n",
      "description: Learn the principles of computer vision and image processing. Topics include filtering, edge detection, feature extraction, image segmentation, object detection, and image classification using CNNs. Hands-on labs in Python leverage OpenCV, scikit-image, and TensorFlow. By project’s end, you will build a pipeline to analyze and classify images, detect objects, and perform real-time video processing.\n",
      "Source: C004\n",
      "Row Content: course_id: C005\n",
      "title: Reinforcement Learning Basics\n",
      "description: Get introduced to reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods. Learn to formulate environments, design reward functions, and implement agents using OpenAI Gym and TensorFlow. Through guided labs you’ll train agents for classic control tasks and grid-world scenarios, exploring exploration-exploitation trade-offs and model-free learning techniques.\n",
      "Source: C005\n"
     ]
    }
   ],
   "source": [
    "# Access rows and their sources\n",
    "for doc in documents[:5]:\n",
    "    print(\"Row Content:\", doc.page_content)  # The content of the row\n",
    "    print(\"Source:\", doc.metadata.get(\"source\"))  # The source of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c0b74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and split 28 document chunks.\n"
     ]
    }
   ],
   "source": [
    "documents = split_documents(documents)\n",
    "print(f\"Loaded and split {len(documents)} document chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a2ee9",
   "metadata": {},
   "source": [
    "# Initialize OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d06d88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI - GPT-4o or GPT-4o-mini\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=MODEL_NAME,\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a80f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651ea594",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a567d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = r\"RAG/chroma_store/\"\n",
    "collection_name = \"courses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "482b03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(documents, index_path, collection_name):\n",
    "    \"\"\"\n",
    "    Create and save a new FAISS vector store from documents.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of document objects to convert to vectors.\n",
    "    \n",
    "    Returns:\n",
    "        None: If successful, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(index_path, exist_ok=True)\n",
    "        vectorstore = Chroma.from_documents(documents, embeddings,persist_directory=index_path,\n",
    "                                             collection_name=collection_name)\n",
    "        save_vectorstore(vectorstore, index_path)\n",
    "        print(\"Vector store created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "def save_vectorstore(vectorstore, index_path):\n",
    "    \"\"\"\n",
    "    Save the FAISS vector store to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore (FAISS): The vector store to save.\n",
    "    \n",
    "    Returns:\n",
    "        None: If successful, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vectorstore.save_local(index_path)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "def load_vectorstore(embeddings, index_path, collection_name):\n",
    "    \"\"\"\n",
    "    Load an existing FAISS vector store.\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Loaded vector store, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Chroma(embedding_function=embeddings,persist_directory=index_path,\n",
    "                      collection_name=collection_name)\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4082b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully.\n",
      "Created and loaded new vector store.\n"
     ]
    }
   ],
   "source": [
    "# Load or create vector store\n",
    "if os.path.exists(index_path) and any(os.listdir(index_path)):\n",
    "    vectorstore = load_vectorstore(embeddings, index_path, collection_name)\n",
    "    vectorstore_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "    print(\"Vector store loaded successfully.\")\n",
    "else:\n",
    "    create_vectorstore(documents, index_path, collection_name)\n",
    "    vectorstore = load_vectorstore(embeddings, index_path, collection_name)\n",
    "    vectorstore_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "    print(\"Created and loaded new vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1292f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Courses:\n",
      "- C001: course_id: C001\n",
      "title: Foundations of Machine Learning\n",
      "- C001: description: Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.\n",
      "- C005: course_id: C005\n",
      "title: Reinforcement Learning Basics\n",
      "description: Get introduced to reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods. Learn to formulate environments, design reward functions, and implement agents using OpenAI Gym and TensorFlow. Through guided labs you’ll train agents for classic control tasks and grid-world scenarios, exploring exploration-exploitation trade-offs and model-free learning techniques.\n",
      "- C002: course_id: C002\n",
      "title: Deep Learning with TensorFlow and Keras\n",
      "description: Explore neural network architectures using TensorFlow and Keras frameworks. This course covers feedforward networks, convolutional neural networks, recurrent neural networks, and transfer learning. Learn to build, train, evaluate, and optimize deep learning models for image classification, sequence modeling, and text processing. Includes hands-on labs and real-world project implementations with interactive exercises.\n",
      "- C003: course_id: C003\n",
      "title: Natural Language Processing Fundamentals\n",
      "description: Dive into NLP techniques for processing and understanding human language. You will learn tokenization, stemming, lemmatization, part-of-speech tagging, named entity recognition, and sentiment analysis. The course includes transformer architectures, attention mechanisms, and fine-tuning pre-trained language models. Hands-on Python labs use Hugging Face and spaCy for end-to-end natural language pipelines and projects.\n"
     ]
    }
   ],
   "source": [
    "# --- Search top-5 similar courses ---\n",
    "user_input_text = \"Foundations of Machine Learning\"\n",
    "results = vectorstore.similarity_search(\n",
    "    query=user_input_text,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "# --- Display recommendations ---\n",
    "print(\"\\nRecommended Courses:\")\n",
    "for doc in results:\n",
    "    name = doc.metadata.get(\"source\")\n",
    "    desc = doc.page_content\n",
    "    print(f\"- {name}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df46335",
   "metadata": {},
   "source": [
    "# RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d37d1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_query(query):\n",
    "    \"\"\"\n",
    "    Validates a user's query by ensuring it is not empty and has at least 15 characters.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input query.\n",
    "    \n",
    "    Returns:\n",
    "        str: The query if valid, or an error message if invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not query:\n",
    "            return \"Query cannot be empty, enter a valid query.\"\n",
    "        elif len(query) < 15:\n",
    "            return \"Query is too short, enter a valid query.\"\n",
    "        else:\n",
    "            return query\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def create_rag_chain(query, relevant_documents):\n",
    "    \"\"\"\n",
    "    Creates and executes a RAG chain to answer a query using retrieved documents.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        relevant_documents (list): List of retrieved document chunks.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated response or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt_template = \"\"\"\n",
    "        Only based on the provided documents, answer the question in points. Do not mention from which document the answer is derived.\n",
    "        Your answer should be based on the documents a few courses that the user can take. Recommend the courses available in the documents.\n",
    "        DO NOT go outside the document for course suggestions. If no suggestions, politely say \"No suggested course available\".\n",
    "        Question: {query}\n",
    "        Documents: {relevant_documents}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        valid_query = validate_query(query)\n",
    "        rag_chain = prompt | llm | StrOutputParser()\n",
    "        return rag_chain.invoke({\"query\": valid_query, \"relevant_documents\": relevant_documents})\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b344b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='d0400fa1-9b5b-4172-828f-94b3924a6a7b', metadata={'row': 6, 'source': 'C007'}, page_content='course_id: C007\\ntitle: Cloud Computing with Azure\\ndescription: Master Microsoft Azure’s core services: virtual machines, Azure Functions, Azure SQL Database, Cosmos DB, and Azure Kubernetes Service. Learn to deploy scalable web applications, configure networking and security, and implement infrastructure-as-code with ARM templates. Hands-on labs guide you through resource provisioning, cost management, and best practices for high availability and disaster recovery in Azure.'), Document(id='c9c93cdd-1ae3-4048-9f58-bd393026496f', metadata={'row': 8, 'source': 'C009'}, page_content='course_id: C009\\ntitle: Containerization with Docker and Kubernetes'), Document(id='7a5e45eb-441e-4186-8457-0cf2037a48a8', metadata={'row': 7, 'source': 'C008'}, page_content='course_id: C008\\ntitle: DevOps Practices and CI/CD'), Document(id='1de8cdaf-c181-44ff-ac00-6e892afa72b2', metadata={'row': 8, 'source': 'C009'}, page_content='title: Containerization with Docker and Kubernetes\\ndescription: Learn container fundamentals with Docker: images, containers, and Compose. Then advance to Kubernetes for orchestration: pods, deployments, services, and ingress. This course covers cluster provisioning, autoscaling, rolling updates, and Helm chart packaging. Hands-on labs deploy microservices architectures on a local or cloud-based Kubernetes cluster, ensuring reliability, scalability, and streamlined DevOps workflows.'), Document(id='198707f6-4af3-44aa-b009-cc338a53b2df', metadata={'row': 7, 'source': 'C008'}, page_content='title: DevOps Practices and CI/CD\\ndescription: Adopt DevOps methodologies to accelerate software delivery. Explore version control with Git, continuous integration with Jenkins or GitHub Actions, infrastructure-as-code with Terraform, and automated testing frameworks. You’ll implement CI/CD pipelines, container registry integration, and blue-green deployments. Through practical labs, learn monitoring with Prometheus and Grafana, fostering a culture of collaboration and rapid iteration.')]\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG chain\n",
    "query = \"\"\"\n",
    "“I know Azure basics and want to manage containers and build CI/CD pipelines.\n",
    "Recommend courses.”\n",
    "\"\"\"\n",
    "relevant_documents = vectorstore_retriever.invoke(query)\n",
    "print(relevant_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7f4755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chain Response:\n",
      "Here are a few recommended courses based on your interest in managing containers and building CI/CD pipelines:\n",
      "\n",
      "1. **Containerization with Docker and Kubernetes**\n",
      "   - Learn container fundamentals with Docker and advance to Kubernetes for orchestration.\n",
      "   - Covers cluster provisioning, autoscaling, rolling updates, and Helm chart packaging.\n",
      "   - Hands-on labs deploy microservices architectures on a local or cloud-based Kubernetes cluster.\n",
      "\n",
      "2. **DevOps Practices and CI/CD**\n",
      "   - Adopt DevOps methodologies to accelerate software delivery.\n",
      "   - Explore version control with Git, continuous integration with Jenkins or GitHub Actions, and infrastructure-as-code with Terraform.\n",
      "   - Implement CI/CD pipelines, container registry integration, and blue-green deployments with practical labs.\n"
     ]
    }
   ],
   "source": [
    "response = create_rag_chain(query, relevant_documents)\n",
    "print(\"RAG Chain Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16adb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
